tibble(
company = x,
measure = y,
auc = results$AUC
)
}
)
?grif
?grid
?expand_grid
expand_grid( names, c("dfb.1_", "dfb.tmst", "diffit", "cov.r", "cook.d", "hat"))
expand_grid(names, method = c("dfb.1_", "dfb.tmst", "diffit", "cov.r", "cook.d", "hat"))
args <- expand_grid(names, method = c("dfb.1_", "dfb.tmst", "diffit", "cov.r", "cook.d", "hat"))
map(args, ~cat(x, y))
map(args, \(x, y) cat(x, y))
args[,2]
lm_mod_training <- map2_dfr(
args[1], args[,2],
function(x, y) {
results <- lm_inf_detection(filter(train, company == x), cv = FALSE, y)
tibble(
company = x,
measure = y,
auc = results$AUC
)
}
)
lm_mod_training <- map2_dfr(
args[1], args[,2],
function(x, y) {
results <- lm_inf_detection(filter(train, company == x), cv = FALSE, method = y)
tibble(
company = x,
measure = y,
auc = results$AUC
)
}
)
lm_inf_detection <- function(data, cv = TRUE, measure = "cook.d") {
## Using a linear model of time and values we are able to identify anomalous values
## from the influence points. This model takes into account if the given point has
## influence from on or all of the measures Cook's distance, Covariance ratio*, dffit*,
## df betas, and/or hat values.
if (cv) {
train <- slice_tail(data, n = floor(.5 * nrow(data)))
} else {
train <- data
}
train_anomaly <- pull(train, anomaly)
n_anom <- sum(train_anomaly)
lm_mod <- lm(value ~ timestamp, train)
inf_point <- as.data.frame(influence.measures(lm_mod)$is.inf)
anom_ind <- inf_point |>
mutate(n = 1:nrow(inf_point)) |>
pivot_longer(-n) |>
group_by(n) |>
filter(name == measure) |>
reframe(n_inf = sum(value)) |>
filter(n_inf > 0) |>
pull(n)
anom_points <- left_join(
train[, c(1, 2, 4)],
tibble(
timestamp = train$timestamp[anom_ind],
anomaly_mod = TRUE
),
by = join_by(timestamp)
)|>
mutate(anomaly_mod = if_else(is.na(anomaly_mod), FALSE, anomaly_mod))
mod_anom <- anom_points |>
pull(anomaly_mod)
mat <- table(mod_anom, train_anomaly)
list(AUC = AUC(mod_anom, train_anomaly),
data = anom_points,
conf_matrix = mat,
true_pos = mat[2, 2] / n_anom)
}
lm_mod_training <- map2_dfr(
args[1], args[,2],
function(x, y) {
results <- lm_inf_detection(filter(train, company == x), cv = FALSE, method = y)
tibble(
company = x,
measure = y,
auc = results$AUC
)
}
)
lm_mod_training <- map2_dfr(
args[1], args[,2],
function(x, y) {
results <- lm_inf_detection(filter(train, company == x), cv = FALSE)
tibble(
company = x,
measure = y,
auc = results$AUC
)
}
)
map2(args[1], args[,2], paste)
map2(args[1], args[,2], \(.x, .y) paste(.x, .y))
args <- expand_grid(names, method = c("dfb.1_", "dfb.tmst", "diffit", "cov.r", "cook.d", "hat"))
args
lm_mod_training <- map2_dfr(
args[1], args[,2],
function(x, y) {
results <- lm_inf_detection(filter(train, company == x), cv = FALSE, y)
tibble(
company = x,
measure = y,
auc = results$AUC
)
}
)
methods_2 <- args |> pull(method)
names_2 <- args |> pull(names)
lm_mod_training <- map2_dfr(
names_2, methods_2,
function(x, y) {
results <- lm_inf_detection(filter(train, company == x), cv = FALSE, y)
tibble(
company = x,
measure = y,
auc = results$AUC
)
}
)
map2(
names_2, methods_2,
function(x, y) {
results <- lm_inf_detection(filter(train, company == x), cv = FALSE, y)
tibble(
company = x,
measure = y,
auc = results$AUC
)
}
)
length(names_2)
length(methods_2)
args <- expand_grid(names, method = c("dfb.1_", "dfb.tmst", "dffit", "cov.r", "cook.d", "hat"))
names_2 <- args |> pull(names)
methods_2 <- args |> pull(method)
lm_mod_training <- map2(
names_2, methods_2,
function(x, y) {
results <- lm_inf_detection(filter(train, company == x), cv = FALSE, y)
tibble(
company = x,
measure = y,
auc = results$AUC
)
}
)
?neuralnetwork
install.packages("tensorflow")
?rnn
library("tensorflow")
?rnn
??rnn
?keras::k_nn
?keras::k_rnn
?isolation.forest
iso_forest_detection <- function(data) {
train <- data |> slice_head(n = ceiling(.5 * nrow(data)))
test <- data |> slice_tail(n = floor(.5 * nrow(data)))
train_anomaly <- pull(train, anomaly)
test_anomaly <- pull(test, anomaly)
n_test_anom <- sum(test_anomaly)
data_without_anomaly <- select(train, -c(anomaly, company))
iso_mod <- isolation.forest(
data_without_anomaly,
ndim = 1, sample_size=256,
ntrees=100,
missing_action="fail"
)
pred_orig <- predict(iso_mod, data_without_anomaly)
pred_orig_test <- predict(iso_mod, select(test, -c(anomaly, company))) >= 0.8
pred_orig_mat <- table(pred_orig_test, test_anomaly)
pred_orig_tp <- ifelse(ncol(pred_orig_mat) == 2 && nrow(pred_orig_mat) == 2
, pred_orig_mat[2, 2] / n_test_anom, 0)
model_dens <- isolation.forest(
data_without_anomaly,
ndim=1, sample_size=256,
ntrees=100,
missing_action="fail",
scoring_metric="density"
)
pred_dens <- predict(model_dens, data_without_anomaly)
pred_dens_test <- predict(model_dens, select(test, -c(anomaly, company))) >= 0.8
pred_dens_mat <- table(pred_dens_test, test_anomaly)
pred_dens_tp <- ifelse(ncol(pred_dens_mat) == 2 && nrow(pred_dens_mat) == 2
, pred_dens_mat[2, 2] / n_test_anom, 0)
model_fcf <- isolation.forest(
data_without_anomaly,
ndim=1, sample_size=256,
prob_pick_pooled_gain=1,
ntrees=100,
missing_action="fail"
)
pred_fcf <- predict(model_fcf, data_without_anomaly)
pred_fcf_test <- predict(model_fcf, select(test, -c(anomaly, company))) >= 0.8
pred_fcf_mat <- table(pred_fcf_test, test_anomaly)
pred_fcf_tp <- ifelse(ncol(pred_fcf_mat) == 2 && nrow(pred_fcf_mat) == 2,
pred_fcf_mat[2, 2] / n_test_anom, 0)
list(
train = tibble(
"Isolation Forest" = AUC(pred_orig, train_anomaly),
"Density Isolation Forest" = AUC(pred_dens, train_anomaly),
"Fair-Cut Forest" = AUC(pred_fcf, train_anomaly)
),
test = tibble(
"Isolation Forest" = AUC(pred_orig_test, test_anomaly),
"Density Isolation Forest" = AUC(pred_dens_test, test_anomaly),
"Fair-Cut Forest" = AUC(pred_fcf_test, test_anomaly)
),
true_pos = tibble(
"Isolation Forest" = pred_orig_tp,
"Density Isolation Forest" = pred_dens_tp,
"Fair-Cut Forest" = pred_fcf_tp
)
)
}
isoForest_tp <- map_dfr(
names,
\(X) {
results <- iso_forest_detection(filter(data, company == X))
cbind(
company = X,
results$true_pos
)
}
) |> pivot_longer(cols = -company) |> pivot_wider(names_from = company)
isoForest_tp
iso_forest_detection <- function(data) {
train <- data |> slice_head(n = ceiling(.5 * nrow(data)))
test <- data |> slice_tail(n = floor(.5 * nrow(data)))
train_anomaly <- pull(train, anomaly)
test_anomaly <- pull(test, anomaly)
n_test_anom <- sum(test_anomaly)
data_without_anomaly <- select(train, -c(anomaly, company))
iso_mod <- isolation.forest(
data_without_anomaly,
ndim = 1, sample_size=256,
ntrees=100,
missing_action="fail"
)
pred_orig <- predict(iso_mod, data_without_anomaly)
pred_orig_test <- predict(iso_mod, select(test, -c(anomaly, company))) >= 0.8
pred_orig_mat <- table(pred_orig_test, test_anomaly)
pred_orig_tp <- ifelse(ncol(pred_orig_mat) == 2 && nrow(pred_orig_mat) == 2
, pred_orig_mat[2, 2] / n_test_anom, 0)
model_dens <- isolation.forest(
data_without_anomaly,
ndim=1, sample_size=256,
ntrees=100,
missing_action="fail",
scoring_metric="density"
)
pred_dens <- predict(model_dens, data_without_anomaly)
pred_dens_test <- predict(model_dens, select(test, -c(anomaly, company))) >= 0.8
pred_dens_mat <- table(pred_dens_test, test_anomaly)
pred_dens_tp <- ifelse(ncol(pred_dens_mat) == 2 && nrow(pred_dens_mat) == 2
, pred_dens_mat[2, 2] / n_test_anom, 0)
model_fcf <- isolation.forest(
data_without_anomaly,
ndim=1, sample_size=128,
prob_pick_pooled_gain=1,
ntrees=100,
missing_action="fail"
)
pred_fcf <- predict(model_fcf, data_without_anomaly)
pred_fcf_test <- predict(model_fcf, select(test, -c(anomaly, company))) >= 0.8
pred_fcf_mat <- table(pred_fcf_test, test_anomaly)
pred_fcf_tp <- ifelse(ncol(pred_fcf_mat) == 2 && nrow(pred_fcf_mat) == 2,
pred_fcf_mat[2, 2] / n_test_anom, 0)
list(
train = tibble(
"Isolation Forest" = AUC(pred_orig, train_anomaly),
"Density Isolation Forest" = AUC(pred_dens, train_anomaly),
"Fair-Cut Forest" = AUC(pred_fcf, train_anomaly)
),
test = tibble(
"Isolation Forest" = AUC(pred_orig_test, test_anomaly),
"Density Isolation Forest" = AUC(pred_dens_test, test_anomaly),
"Fair-Cut Forest" = AUC(pred_fcf_test, test_anomaly)
),
true_pos = tibble(
"Isolation Forest" = pred_orig_tp,
"Density Isolation Forest" = pred_dens_tp,
"Fair-Cut Forest" = pred_fcf_tp
)
)
}
isoForest_tp <- map_dfr(
names,
\(X) {
results <- iso_forest_detection(filter(data, company == X))
cbind(
company = X,
results$true_pos
)
}
) |> pivot_longer(cols = -company) |> pivot_wider(names_from = company)
isoForest_tp
iso_forest_detection <- function(data) {
train <- data |> slice_head(n = ceiling(.5 * nrow(data)))
test <- data |> slice_tail(n = floor(.5 * nrow(data)))
train_anomaly <- pull(train, anomaly)
test_anomaly <- pull(test, anomaly)
n_test_anom <- sum(test_anomaly)
data_without_anomaly <- select(train, -c(anomaly, company))
iso_mod <- isolation.forest(
data_without_anomaly,
ndim = 1, sample_size=256,
ntrees=100,
missing_action="fail"
)
pred_orig <- predict(iso_mod, data_without_anomaly)
pred_orig_test <- predict(iso_mod, select(test, -c(anomaly, company))) >= 0.8
pred_orig_mat <- table(pred_orig_test, test_anomaly)
pred_orig_tp <- ifelse(ncol(pred_orig_mat) == 2 && nrow(pred_orig_mat) == 2
, pred_orig_mat[2, 2] / n_test_anom, 0)
model_dens <- isolation.forest(
data_without_anomaly,
ndim=1, sample_size=256,
ntrees=100,
missing_action="fail",
scoring_metric="density"
)
pred_dens <- predict(model_dens, data_without_anomaly)
pred_dens_test <- predict(model_dens, select(test, -c(anomaly, company))) >= 0.8
pred_dens_mat <- table(pred_dens_test, test_anomaly)
pred_dens_tp <- ifelse(ncol(pred_dens_mat) == 2 && nrow(pred_dens_mat) == 2
, pred_dens_mat[2, 2] / n_test_anom, 0)
model_fcf <- isolation.forest(
data_without_anomaly,
ndim=1, sample_size=256,
prob_pick_pooled_gain=1,
ntrees=100,
missing_action="fail"
)
pred_fcf <- predict(model_fcf, data_without_anomaly)
pred_fcf_test <- predict(model_fcf, select(test, -c(anomaly, company))) >= 0.8
pred_fcf_mat <- table(pred_fcf_test, test_anomaly)
pred_fcf_tp <- ifelse(ncol(pred_fcf_mat) == 2 && nrow(pred_fcf_mat) == 2,
pred_fcf_mat[2, 2] / n_test_anom, 0)
list(
train = tibble(
"Isolation Forest" = AUC(pred_orig, train_anomaly),
"Density Isolation Forest" = AUC(pred_dens, train_anomaly),
"Fair-Cut Forest" = AUC(pred_fcf, train_anomaly)
),
test = tibble(
"Isolation Forest" = AUC(pred_orig_test, test_anomaly),
"Density Isolation Forest" = AUC(pred_dens_test, test_anomaly),
"Fair-Cut Forest" = AUC(pred_fcf_test, test_anomaly)
),
true_pos = tibble(
"Isolation Forest" = pred_orig_tp,
"Density Isolation Forest" = pred_dens_tp,
"Fair-Cut Forest" = pred_fcf_tp
)
)
}
isoForest_auc <- map_dfr(
names,
\(X) {
results <- iso_forest_detection(filter(data, company == X))
cbind(
company = X,
results$test
)
}
) |> pivot_longer(cols = -company) |> pivot_wider(names_from = company)
isoForest_auc
data |> filter(company == "UPS")
data |> filter(company == "UPS") |> slice()
data |> filter(company == "UPS") |> slice_tail(n = round(.5 * nrow(data)))
data |> filter(company == "UPS") |> slice_tail(n = round(.5 * nrow(data))) |> pull(anomaly) |> sum()
data |> filter(company == "UPS") |> slice_tail(n = round(.5 * nrow(apple))) |> pull(anomaly) |> sum()
data |> filter(company == "UPS") |> which(anomaly == TRUE)
data |> filter(company == "UPS") |> which(anomaly)
data |> filter(company == "UPS") |> pull(anomaly) |> which()
- No model does any well on UPS.
round(.5 * nrow(apple))
dat
data$company |> unique()
data <- apple
data$company |> unique()
train <- data |> slice_head(n = ceiling(.5 * nrow(data)))
n_train_anom <- sum(pull(train, anomaly))
normal_train <- train |> filter(!anomaly) |>
select(-c(anomaly, company)) |>
mutate(timestamp = as.numeric(timestamp))
autoencoder(normal_train)
autoencoder(normal_train, hidden.layers = NA)
ae <- autoencoder(normal_train, hidden.layers = NA)
plot(ae)
reconstruction_plot(ae, train)
data_without_anomaly <- select(train, -c(anomaly, company)) |>
mutate(timestamp = as.numeric(timestamp))
reconstruction_plot(ae, data_without_anomaly)
reconstruct(ae, data_without_anomaly)
library("keras")
library("tensorflow")
use_condaenv("keras-tf", required = T)
model <- keras_model_sequential()
install_tensorflow()
?neuralnetwork
nn_mod <- neuralnetwork(data_without_anomaly, train_anomaly, hidden.layers = 1)
nn_mod
nn_mod |> summary()
# Chunk 1
#| include: false
library("tidyverse"); theme_set(theme_minimal())
library("MLmetrics")
source("functions.R")
data <- read_csv("data/combined_data.csv")
# Chunk 2
data |> ggplot(aes(x = timestamp, y = value)) +
geom_line(aes(color = company), alpha = .6) +
geom_point(data = filter(data, anomaly), shape = 4) +
facet_wrap(vars(company), scales = "free_y") +
scale_color_viridis_d(option = "H") +
labs(title = "Time plot of Twitter tags with anomalies",
x = "Time", y = "Twitter tags") +
theme(legend.position = "none")
apple_1 <- filter(data, company == "AAPL") |> slice_head(n =3180)
lm_res <- lm_inf_detection(apple_1, cv = FALSE)$data
lm_res |>
ggplot(aes(x = timestamp, y = value)) +
geom_line() +
geom_smooth(method = "lm") +
geom_point(data = filter(lm_res, anomaly_mod), color = "forestgreen", alpha = .5) +
geom_point(data = filter(lm_res, anomaly), color = "firebrick", shape = 4) +
labs(title = "Apple linear regression model",
subtitle = "Feb. 27 to Mar. 10",
x = "Date", y = "Twitter tag count")
#| fig-height: 7
stl(co2, t.window = 12, s.window = "periodic") |>
plot()
apple_1 <- filter(data, company == "AAPL") |> slice_head(n =3180)
lm_res <- lm_inf_detection(apple_1, cv = FALSE)$data
lm_res |>
ggplot(aes(x = timestamp, y = value)) +
geom_line() +
geom_smooth(method = "lm") +
geom_point(data = filter(lm_res, anomaly_mod), color = "forestgreen", alpha = .5) +
geom_point(data = filter(lm_res, anomaly), color = "firebrick", shape = 4) +
labs(title = "Apple linear regression model",
subtitle = "Feb. 27 to Mar. 10",
x = "Date", y = "Twitter tag count")
data |> ggplot(aes(x = timestamp, y = value)) +
geom_line(aes(color = company), alpha = .6) +
geom_point(data = filter(data, anomaly), shape = 4) +
facet_wrap(vars(company), scales = "free_y") +
scale_color_viridis_d(option = "H") +
labs(title = "Time plot of Twitter tags with anomalies",
x = "Time", y = "Twitter tags") +
theme(legend.position = "none")
library("tidyverse"); theme_set(theme_minimal())
library("ggdensity")
library("timetk")
library("isotree")
library("MLmetrics")
library("ANN2")
data <- read_csv("data/combined_data.csv")
data <- data |> filter(comany == "AAPL")
data <- data |> filter(company == "AAPL")
train <- data |> slice_head(n = ceiling(.5 * nrow(data)))
n_train_anom <- sum(pull(train, anomaly))
test <- data |> slice_tail(n = floor(.5 * nrow(data)))
n_test_anom <- sum(pull(test, anomaly))
n_test_anom
train_anomaly <- train |> pull(anomaly)
data_without_anomaly <- select(train, -c(anomaly, company)) |>
mutate(timestamp = as.numeric(timestamp))
normal_train <- train |> filter(!anomaly) |>
select(-c(anomaly, company)) |>
mutate(timestamp = as.numeric(timestamp))
# nn_mod <- neuralnetwork(data_without_anomaly, train_anomaly, hidden.layers = 1)
nn_mod <- autoencoder(data_without_anomaly, hidden.layers = c(2, 2))
test_without_anomaly <- select(test, -c(anomaly, company)) |>
mutate(timestamp = as.numeric(timestamp))
train_pred <- predict(nn_mod, data_without_anomaly)$prediction
test_pred <- predict(nn_mod, test_without_anomaly)$prediction
test_mat <- table(test$anomaly, test_pred)
test_pred
str(nn_mod)
?predict.ANN
predict(nn_mod, test_without_anomaly)
predict(nn_mod, test_without_anomaly) |> str()
plot(nn_mod)
reconstruction_plot(nn_mod)
reconstruction_plot(nn_mod, data_without_anomaly)
compression_plot(nn_mod, data_without_anomaly)
nn_mod <- neuralnetwork(data_without_anomaly, train_anomaly, hidden.layers = 1)
test_pred <- predict(nn_mod, test_without_anomaly)$prediction
test_mat <- table(test$anomaly, test_pred)
true_pos <- ifelse(ncol(test_mat) == 2, test_mat[2, 2] / n_test_anom, 0.0)
true_pos
AUC(test_pred, test$anomaly)
nn_mod <- neuralnetwork(data_without_anomaly, train_anomaly, hidden.layers = c(2, 2))
test_pred <- predict(nn_mod, test_without_anomaly)$prediction
(true_pos <- ifelse(ncol(test_mat) == 2, test_mat[2, 2] / n_test_anom, 0.0))
AUC(test_pred, test$anomaly)
nn_mod <- neuralnetwork(data_without_anomaly, train_anomaly, hidden.layers = c(2))
test_pred <- predict(nn_mod, test_without_anomaly)$prediction
(true_pos <- ifelse(ncol(test_mat) == 2, test_mat[2, 2] / n_test_anom, 0.0))
AUC(test_pred, test$anomaly)
nn_mod <- neuralnetwork(data_without_anomaly, train_anomaly, hidden.layers = 1)
